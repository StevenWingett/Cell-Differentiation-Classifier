{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962d5f87-cfae-4154-8331-45180bc1366a",
   "metadata": {},
   "source": [
    "# Basic Prediction Summary\n",
    "Takes as input simple summary results of the format:\n",
    "\n",
    "|expected|predicted|\n",
    "|--------|---------|\n",
    "|1       |    0    |\n",
    "|1       |    1    |\n",
    "|0       |    0    |\n",
    "|0       |    1    |\n",
    "|1       |    1    |\n",
    "\n",
    "Returns a basic classificiation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0201d-f294-4785-8e5e-27f697b41dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1420b276-ea62-41cc-9ded-e23782c370ca",
   "metadata": {},
   "source": [
    "## Setup (edit as required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9809e7-ad4c-4a97-8b2a-ffb5fff4f3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup (edit as required)\n",
    "expected_predicted_file = '/Users/swingett/Desktop/predicted_coeff_pred.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4827c3e-70ab-46f2-b94d-801b693447ef",
   "metadata": {},
   "source": [
    "## Read in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af4ded-ed44-4829-8cf4-fae070b8e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in results\n",
    "expected_predicted = pd.read_csv(expected_predicted_file, sep=\"\\t\")\n",
    "print(\"Reading in: \" + expected_predicted_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b473edb-7427-47ff-85bd-a2b80c2d5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "cm = confusion_matrix(expected_predicted['expected'], expected_predicted['predicted'])\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap=plt.cm.Blues, fmt='g')\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['Undifferentiated', 'Differentiated'])\n",
    "ax.yaxis.set_ticklabels(['Undifferentiated', 'Differentiated'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b96aca-c909-44cb-8f76-d866c7fd29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "acc = accuracy_score(expected_predicted['expected'], expected_predicted['predicted'])\n",
    "print('Accuracy: ', acc)\n",
    "print()\n",
    "\n",
    "# Calculate Cohen's Kappa score\n",
    "cka = cohen_kappa_score(expected_predicted['expected'], expected_predicted['predicted'])\n",
    "print(\"Cohen suggested the Kappa result be interpreted as follows: \")\n",
    "print(\"values ≤ 0 as indicating no agreement\\n0.01–0.20 as none to slight\\n0.21–0.40 as fair\")\n",
    "print(\"0.41– 0.60 as moderate\\n0.61–0.80 as substantial\\n0.81–1.00 as almost perfect agreement.\\n\")\n",
    "print('Cohen\\'s Kappa: ', cka)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
