{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ca083-ba45-4dea-9042-40efb2fecf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier script\n",
    "# Takes as input:\n",
    "#                 i) z-scores of expression\n",
    "#                 ii) metadata\n",
    "#                 iii) list of genes and correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ced3c-ba7e-4505-8afd-6fd83f7a3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae26194-a159-4e69-bc26-60f3fe60bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Input dataset\n",
    "#expression_data_file = 'salmon.merged.gene_tpm.log2_tmp_plus_1.downsized.z_scores.tsv.gz'\n",
    "expression_data_file = 'salmon.merged.gene_tpm.log2_tmp_plus_1.retention_group_filtered.z_scores.tsv.gz'\n",
    "\n",
    "\n",
    "# Metadata\n",
    "metadata_file = 'dataset_summary.tsv'\n",
    "\n",
    "# Correlation file\n",
    "correlation_file = 'salmon.merged.gene_tpm.log2_tmp_plus_1.retention_group_filtered.correlation.tsv.gz'\n",
    "\n",
    "# FDR\n",
    "fdr_threshold = 0.05\n",
    "\n",
    "# Classifier iterations\n",
    "classifier_iterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f3792-224b-49f1-8565-9a62337b2a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "print(\"Reading in metadata: \" + metadata_file)\n",
    "metadata = pd.read_csv(metadata_file, sep=\"\\t\")\n",
    "print(f'Metadata number of Accessions: {metadata.shape[0]}')\n",
    "print()\n",
    "\n",
    "print(\"Reading in expression file: \" + expression_data_file)\n",
    "expression_data = pd.read_csv(expression_data_file, sep=\"\\t\")\n",
    "print(f'Number of cell lines: {expression_data.shape[1] - 2}')\n",
    "print(f'Number of genes: {expression_data.shape[0]}')\n",
    "print()\n",
    "\n",
    "print(\"Reading in correlation file: \" + correlation_file)\n",
    "correlation_data = pd.read_csv(correlation_file, sep=\"\\t\")\n",
    "print(f'Number of genes in correlation file genes: {correlation_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774a500-05fc-4621-8706-1c7a2c464d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score histogram\n",
    "plot_data = (expression_data\n",
    "                .iloc[:, 2:]\n",
    "                .to_numpy()\n",
    "                .flatten()\n",
    "            )\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.hist(plot_data, bins=100)\n",
    "plt.xlabel('z-score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f3f94-4d4b-4ce1-a77e-2e1d5451bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative distribution plot\n",
    "plt.figure(figsize=(7,7))\n",
    "plot=sns.ecdfplot(data=expression_data.iloc[:, 2:], legend=False)\n",
    "plt.xlabel('z-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef8286-a921-4d0a-bf74-cd994196a81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter to obtain only correlated genes\n",
    "print(f'Filtering by FDR threshold ({fdr_threshold})')\n",
    "\n",
    "correlation_data = (correlation_data\n",
    "                        .query('q <= @fdr_threshold')\n",
    "                        .loc[:,'target_gene_id']\n",
    "                    )\n",
    "\n",
    "print(f'Number of correlated genes identified: {correlation_data.shape[0]}')\n",
    "\n",
    "boolean_to_select = (expression_data\n",
    "                         .loc[:, 'gene_id']\n",
    "                         .isin(correlation_data)\n",
    "                    )\n",
    "\n",
    "expression_data = expression_data[boolean_to_select]\n",
    "expression_data = expression_data.reset_index(drop=True)\n",
    "\n",
    "print(f'Number of genes selected from expression file: {expression_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b250f-d3ae-4bae-9053-35c18a283672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score histogram after filtering\n",
    "plot_data = (expression_data\n",
    "                .iloc[:, 2:]\n",
    "                .to_numpy()\n",
    "                .flatten()\n",
    "            )\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.hist(plot_data, bins=100)\n",
    "plt.xlabel('z-score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f127ade4-ac89-47e2-b201-e814ae321a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative distribution plot after filtering\n",
    "plt.figure(figsize=(7,7))\n",
    "plot=sns.ecdfplot(data=expression_data.iloc[:, 2:], legend=False)\n",
    "plt.xlabel('z-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216cfb5-eec3-42bf-86d9-758c736a0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit Metadata\n",
    "metadata = metadata.loc[:, ['Accession', 'Cell_line', 'Diff_efficiency']]\n",
    "\n",
    "# Extract accessions of interest\n",
    "boolean_to_select = (metadata\n",
    "                         .loc[:, 'Accession']\n",
    "                         .isin(expression_data.iloc[:, 2:].columns)\n",
    "                    )\n",
    "\n",
    "metadata = metadata[boolean_to_select]\n",
    "\n",
    "# Differentition success (score > 0.2)\n",
    "metadata['Success'] = np.where(metadata['Diff_efficiency'] >= 0.2, 1, 0)\n",
    "metadata = metadata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff5dac-f247-4f70-91f5-bbf2d75443eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dateframe of the accession to predict and associated success/failure training datasets\n",
    "# Work through metadata selecting accession of interest and training data\n",
    "\n",
    "training_datasets = pd.DataFrame()\n",
    "\n",
    "for iteration in range(1, classifier_iterations + 1):\n",
    "    \n",
    "    if iteration % 5 == 0:\n",
    "        print(f'Iteration: {iteration}')\n",
    "    \n",
    "    for accession_of_interest in metadata.loc[:, 'Accession']:\n",
    "        #accession_of_interest = 'ERR1203463'\n",
    "\n",
    "        # When training the classifier, do NOT include accessions from the \n",
    "        # same cell line in training set.\n",
    "        cell_line_ignore = (metadata       \n",
    "                                .query('Accession == @accession_of_interest')\n",
    "                                .loc[:, 'Cell_line']\n",
    "                                .iloc[0]\n",
    "                           )\n",
    "        # Select Success/Failure training sets\n",
    "        # Do not use the same cell line more than once\n",
    "        # Shufle so the same accession for each cell line is not used every time\n",
    "        training_accessions_success = (metadata\n",
    "                                           .query('Success == 1')\n",
    "                                           .query('Cell_line != @cell_line_ignore')\n",
    "                                           .sample(frac=1)   #Shuffle\n",
    "                                           .drop_duplicates(subset='Cell_line')\n",
    "                                      )\n",
    "\n",
    "        training_accessions_fail = (metadata\n",
    "                                           .query('Success == 0')\n",
    "                                           .query('Cell_line != @cell_line_ignore')\n",
    "                                           .sample(frac=1)   #Shuffle\n",
    "                                           .drop_duplicates(subset='Cell_line')\n",
    "                                      )\n",
    "\n",
    "        # Make the training datasets equal size\n",
    "        dataset_size = min(training_accessions_success.shape[0],\n",
    "                           training_accessions_fail.shape[0])\n",
    "\n",
    "        training_accessions_success = (training_accessions_success\n",
    "                                           .head(dataset_size)\n",
    "                                           .loc[:, 'Accession']\n",
    "                                      )\n",
    "        training_accessions_fail = (training_accessions_fail\n",
    "                                        .head(dataset_size)\n",
    "                                        .loc[:, 'Accession']\n",
    "                                   )\n",
    "\n",
    "        training_accessions_success = pd.DataFrame(training_accessions_success)\n",
    "        training_accessions_success['accession_of_interest'] = accession_of_interest\n",
    "        training_accessions_success['status_training_accession'] = 1\n",
    "        training_accessions_success = training_accessions_success.rename(columns={'Accession': 'training_accession'})\n",
    "        training_accessions_success['Iteration'] = iteration\n",
    "        training_datasets = pd.concat([training_datasets, training_accessions_success], ignore_index=True)\n",
    "\n",
    "        training_accessions_fail = pd.DataFrame(training_accessions_fail)\n",
    "        training_accessions_fail['accession_of_interest'] = accession_of_interest\n",
    "        training_accessions_fail['status_training_accession'] = 0\n",
    "        training_accessions_fail = training_accessions_fail.rename(columns={'Accession': 'training_accession'})\n",
    "        training_accessions_fail['Iteration'] = iteration\n",
    "        \n",
    "        training_datasets = pd.concat([training_datasets, training_accessions_fail], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435d5b5-452c-4c16-a123-ea3b4515baf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the logistic regression\n",
    "logistic_regression_all_results = pd.DataFrame()\n",
    "coefficients = pd.DataFrame()  #Stores coefficients for later use\n",
    "\n",
    "for iteration in range(1, classifier_iterations + 1):\n",
    "    if iteration % 5 == 0:\n",
    "        print(f'Iteration: {iteration}')\n",
    "        \n",
    "    for target_accession in expression_data.columns.to_list()[2:]:\n",
    "        #target_accession = 'ERR1203463'\n",
    "\n",
    "\n",
    "        # Extract relevant the information\n",
    "        target_expression = expression_data.loc[:, target_accession]\n",
    "        target_success = (metadata\n",
    "                            .query('Accession == @target_accession')\n",
    "                            .loc[:, 'Success']\n",
    "                            .iloc[0]\n",
    "                        )\n",
    "\n",
    "        training_data_accessions = (training_datasets\n",
    "                                        .query('Iteration == @iteration')\n",
    "                                        .query('accession_of_interest == @accession_of_interest')\n",
    "                                        .loc[:, 'training_accession']\n",
    "                                        .drop_duplicates()  \n",
    "                                    )\n",
    "\n",
    "        columns_to_select = training_data_accessions.to_list()\n",
    "        columns_to_select = ['gene_id'] + columns_to_select\n",
    "        training_expression = (expression_data\n",
    "                                   .loc[:, columns_to_select]\n",
    "                                   .transpose()\n",
    "                              )\n",
    "        training_expression.columns = training_expression.loc['gene_id', :]\n",
    "        training_expression = training_expression.iloc[1:, :] # Remove row 1\n",
    "\n",
    "        # Restructure data\n",
    "        training_success =  (metadata\n",
    "                             .loc[:, ['Accession', 'Success']]\n",
    "                             .transpose()\n",
    "                            )\n",
    "\n",
    "        training_success.columns = metadata.loc[:, 'Accession']\n",
    "        training_success = (training_success\n",
    "                            .loc['Success', :]\n",
    "                            .loc[training_data_accessions.to_list()]  #re-order\n",
    "                            )\n",
    "\n",
    "        # Convert to Numpy format\n",
    "        training_expression = (training_expression\n",
    "                                .to_numpy()\n",
    "                                .astype('int')\n",
    "                              )\n",
    "\n",
    "        training_success = (training_success\n",
    "                                .to_numpy()\n",
    "                                .astype('int')\n",
    "                           )\n",
    "\n",
    "        target_expression = (target_expression.to_numpy()\n",
    "                                .reshape(1, -1) \n",
    "                            )\n",
    "\n",
    "        #Run logistic regression\n",
    "        lreg = LogisticRegression(solver='liblinear', max_iter=100, penalty='l1')\n",
    "        lreg.fit(training_expression, training_success)\n",
    "\n",
    "        predicted = lreg.predict(target_expression)\n",
    "        expected = target_success\n",
    "\n",
    "        predicted_prob= lreg.predict_proba(target_expression)\n",
    "        predicted_prob = predicted_prob[0:, 1]\n",
    "\n",
    "        logistic_regression_result = pd.DataFrame({ 'Iteration': iteration,\n",
    "                                                    'Accession' : [target_accession],\n",
    "                                                    'Expected' : target_success,\n",
    "                                                    'Predicted_p_value' : predicted_prob}\n",
    "                                                 )\n",
    "\n",
    "        logistic_regression_all_results = pd.concat([logistic_regression_all_results, \n",
    "                                                     logistic_regression_result],\n",
    "                                                       ignore_index=True)\n",
    "        \n",
    "        # Store coefficients and intercepts\n",
    "        coeffs_current = pd.DataFrame(lreg.coef_[0], columns=['coefficient'])\n",
    "        coeffs_current['gene_id'] = expression_data.loc[:, 'gene_id']\n",
    "        coeffs_current['accession'] = target_accession\n",
    "        coeffs_current['iteration'] = iteration\n",
    "\n",
    "        coeffs_current = coeffs_current.query('coefficient != 0')  #Remove uniformative coefficients\n",
    "        \n",
    "        intercept_current = pd.DataFrame(\n",
    "            {'coefficient' : [lreg.intercept_[0]],\n",
    "             'gene_id' : ['INTERCEPT'],\n",
    "             'accession' : [target_accession],\n",
    "             'iteration' : [iteration]\n",
    "            })\n",
    "        \n",
    "        coefficients = pd.concat([coefficients, intercept_current], ignore_index=True)\n",
    "        coefficients = pd.concat([coefficients, coeffs_current], ignore_index=True)\n",
    "        \n",
    "coefficients = coefficients.loc[:, ['iteration',    #Reorder\n",
    "                                     'accession',\n",
    "                                     'gene_id',\n",
    "                                     'coefficient'\n",
    "                                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8a0bd-e82d-45bf-abe6-3e053f49b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out results\n",
    "outfile = 'classifier_results.tsv.gz'\n",
    "print(\"Writing results to: \" + outfile)\n",
    "logistic_regression_all_results.to_csv(outfile,\n",
    "                                       index=False, \n",
    "                                       compression='gzip', \n",
    "                                       sep=\"\\t\")\n",
    "\n",
    "outfile = 'classifier_coefficients.tsv.gz'\n",
    "print(\"Writing coefficients to: \" + outfile)\n",
    "coefficients.to_csv(outfile, index=False, compression='gzip', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0988034-35cc-41c1-b5d5-3d3b258766ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log of the datasets used in training the logistic regression classifier\n",
    "outfile = 'classifier_training_log.tsv.gz'\n",
    "print(\"Writing a log of the datasets used in training the logistic regression classifier: \" + outfile)\n",
    "training_datasets.to_csv(outfile,\n",
    "                            index=False, \n",
    "                            compression='gzip', \n",
    "                            sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0f1f5-303b-4f28-8e5f-5ab52055bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab57894-ebfa-4d13-8035-7020c0a3c7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
