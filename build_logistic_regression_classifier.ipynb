{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5859b9-3bad-41df-a4e3-6ea78410b958",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier of Differentiation in Cell Lines using Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf811a-98e0-42a7-9bbb-9e6a25b0037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bda8f052-c679-4541-ac71-8606231b8131",
   "metadata": {},
   "source": [
    "## Setup(edit as required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56715d5b-54e1-44c3-8283-9edc5c84b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (edit as required)\n",
    "expression_datafile = 'classifier_input.tsv.gz'\n",
    "retention_groups_to_process = (0, )    #Tuple of all retention groups to include (remember trailing comma)\n",
    "expression_threshold = 2.75\n",
    "differentiation_threshold = 0.2  #Set in paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67750eb5-bd72-444b-9017-da1e28e27f4c",
   "metadata": {},
   "source": [
    "## Data import, QC and summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1c9cf-338a-434d-82b6-857c14a7f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "expression_data = pd.read_csv(expression_datafile, sep=\"\\t\")\n",
    "print(\"Reading in: \" + expression_datafile)\n",
    "print(\"Number of different accessions: \" + str(expression_data['Accession'].drop_duplicates().count()))\n",
    "print(\"Number of different cell lines: \" + str(expression_data['Cell_line'].drop_duplicates().count()))\n",
    "print(\"Number of different transcripts: \" + str(expression_data['target_id'].drop_duplicates().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4111de-33e9-457b-a64d-f0a53acd602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log10 tpm histogram\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(expression_data['log10_tpm'], bins=100)\n",
    "plt.xlabel('Log10(tpm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a9c03-b922-48fd-adc7-766bae776f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot=sns.ecdfplot(data=expression_data, \n",
    "                  x=\"log10_tpm\", \n",
    "                  hue=\"Accession\",\n",
    "                 legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb727f-4f77-424a-b90a-148a9e4a7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score overview\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(expression_data['z_score'], bins=100)\n",
    "plt.xlabel('Z-score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e586a-8f3e-4035-9609-ac57f49e4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on i) cell lines and ii) expression values\n",
    "boolean_series = expression_data['Retention_group'].isin(retention_groups_to_process)\n",
    "expression_data = expression_data[boolean_series]\n",
    "\n",
    "expression_data = expression_data[expression_data.target_max_log10_tpm >= expression_threshold]\n",
    "expression_data =  expression_data.sort_values(by=['Accession', 'target_id'])    #Useful when re-shaping\n",
    "\n",
    "print(\"Analysis using:\")\n",
    "print(\"Number of different accessions: \" + str(expression_data['Accession'].drop_duplicates().count()))\n",
    "print(\"Number of different cell lines: \" + str(expression_data['Cell_line'].drop_duplicates().count()))\n",
    "print(\"Number of different transcripts: \" + str(expression_data['target_id'].drop_duplicates().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3367a2-35b8-4a5b-a309-54e06f2a17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log10 histogram after filtering\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(expression_data['log10_tpm'], bins=100)\n",
    "plt.xlabel('Log10(tpm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d89199-e226-4c7a-9d77-3cf06f587cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Distribution after filtering\n",
    "plt.figure(figsize=(8,8))\n",
    "plot=sns.ecdfplot(data=expression_data, \n",
    "                  x=\"log10_tpm\", \n",
    "                  hue=\"Accession\",\n",
    "                 legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae344f-17d8-4f43-a65a-9c44fc8f325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(expression_data['z_score'], bins=100)\n",
    "plt.xlabel('Z-score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc158ac-ecb9-4d43-a7bb-e07c39d725c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column that specifies whether an accession has undergone differentiation\n",
    "expression_data['Differentiated'] = np.where(expression_data['Diff_efficiency'] > differentiation_threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe31c35-138a-479b-9f6d-c97f2f66e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a simplified file in user-friendly format for analysis in other tools (e.g. R, Excel)\n",
    "\n",
    "#Log10(TPM+1)\n",
    "data_for_external_analysis = expression_data\n",
    "data_for_external_analysis['Cell_Sample'] = data_for_external_analysis['Accession'] + \"_\" + data_for_external_analysis['Cell_line']\n",
    "\n",
    "data_for_external_analysis = (data_for_external_analysis\n",
    "        .loc[:, ['Cell_Sample', 'target_id', 'log10_tpm']]\n",
    "        .pivot(index=\"target_id\", columns='Cell_Sample', values='log10_tpm')\n",
    "    )\n",
    "\n",
    "\n",
    "data_for_external_analysis['Cell_Sample'] = data_for_external_analysis.index\n",
    "first_column = data_for_external_analysis.pop('Cell_Sample')\n",
    "data_for_external_analysis.insert(0, 'Cell_Sample', first_column)\n",
    "\n",
    "\n",
    "#Write out the result\n",
    "external_analysis_file = 'external_analysis_data_log10_tpm.tsv.gz'\n",
    "print(\"Writing results to: \" + external_analysis_file)\n",
    "data_for_external_analysis.to_csv(external_analysis_file, index=False, compression='gzip', sep=\"\\t\")\n",
    "\n",
    "#Z-scores\n",
    "data_for_external_analysis = expression_data\n",
    "data_for_external_analysis['Cell_Sample'] = data_for_external_analysis['Accession'] + \"_\" + data_for_external_analysis['Cell_line']\n",
    "\n",
    "data_for_external_analysis = (data_for_external_analysis\n",
    "        .loc[:, ['Cell_Sample', 'target_id', 'z_score']]\n",
    "        .pivot(index=\"target_id\", columns='Cell_Sample', values='z_score')\n",
    "    )\n",
    "\n",
    "data_for_external_analysis['Cell_Sample'] = data_for_external_analysis.index\n",
    "first_column = data_for_external_analysis.pop('Cell_Sample')\n",
    "data_for_external_analysis.insert(0, 'Cell_Sample', first_column)\n",
    "\n",
    "#Write out the result\n",
    "external_analysis_file = 'external_analysis_data_z_score.tsv.gz'\n",
    "print(\"Writing results to: \" + external_analysis_file)\n",
    "data_for_external_analysis.to_csv(external_analysis_file, index=False, compression='gzip', sep=\"\\t\")\n",
    "\n",
    "del(data_for_external_analysis)\n",
    "del(first_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e06679-f815-4366-bfd6-9e6123f8f3a4",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d5b45-bd5f-4f64-97ab-8a8429f8da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn to plot the class distribution\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.countplot(x='Differentiated', \n",
    "              data=expression_data[['Accession', 'Differentiated']].drop_duplicates())\n",
    "plt.title('Class distribution: 0=Undifferentiated, 1=Differentiated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede57dd-c3ab-4dc2-bc74-39d48b235d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-shape the expression data to a format usable by ML tools\n",
    "#This creates a standardised datastructure / naming convention where:\n",
    "# X: input parameters\n",
    "# y: target (expected) results (i.e. boolean of whether accession is differentiated)\n",
    "X = (expression_data\n",
    "        .loc[:, ['Accession', 'target_id', 'z_score']]\n",
    "        .pivot(index=\"Accession\", columns='target_id', values='z_score')\n",
    "        .to_numpy()\n",
    "    )\n",
    "\n",
    "#Determine the differentiation scores in a numpy format\n",
    "y = (expression_data\n",
    "        .loc[:, ['Accession', 'Differentiated']]\n",
    "        .drop_duplicates()\n",
    "        .loc[:, 'Differentiated']\n",
    "        .to_numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62e689-afe1-4023-823d-654eec5ce723",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Leave-one-out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a7095-2f4d-44a4-a260-98f3b7775d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform logistic regression with a leave-one-out cross validation technique\n",
    "cross_validation = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92437714-ca1e-4bf9-91de-da6c88e6214e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(solver='liblinear', max_iter=100, penalty='l1')\n",
    "scores = cross_val_score(lreg, X, y, cv=cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0c46e-e257-4cd6-8c32-9706b87e9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic regression results:\")\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f7bfe-9980-4b48-aa8a-f5a56881c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "predicted = cross_val_predict(lreg, X, y, cv=cross_validation)\n",
    "predictions_probabilities = cross_val_predict(lreg, X, y, cv=cross_validation, method=\"predict_proba\")\n",
    "predictions_probabilities = predictions_probabilities[0:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61f6cc-a4ae-4c0d-9a96-e6bc01c3694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "cm = confusion_matrix(y, predicted)\n",
    "\n",
    "plt.figure(figsize=(10.5, 7.5))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap=plt.cm.Blues, fmt='g')\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['Undifferentiated', 'Differentiated'])\n",
    "ax.yaxis.set_ticklabels(['Undifferentiated', 'Differentiated'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd2118-cc6f-49d4-b5d1-f22783bbafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "acc = accuracy_score(y, predicted)\n",
    "print('Accuracy: ', acc)\n",
    "\n",
    "# Calculate Cohen's Kappa score\n",
    "cka = cohen_kappa_score(y, predicted)\n",
    "print('Cohen\\'s Kappa: ', cka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da88ca-6699-41d6-bc7f-adc67f0a842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a ROC AUC plot\n",
    "fpr, tpr, threshold = metrics.roc_curve(y, predicted)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--', label = 'Random chance')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bfc6a-292b-43b3-a602-201df230440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a PR plot\n",
    "precision, recall, _ = metrics.precision_recall_curve(y, predicted)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736cec9-4797-4f45-b34b-b6a434d3a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot differentition efficiency against predicted values\n",
    "plt.figure(figsize=(14, 10)) \n",
    "real_differentiation_scores = (expression_data\n",
    "                                .loc[:, ['Accession', 'Diff_efficiency', 'Differentiated']]\n",
    "                                .drop_duplicates()\n",
    "                              )\n",
    "\n",
    "plt.scatter(x=real_differentiation_scores['Diff_efficiency'], \n",
    "            y=predictions_probabilities,\n",
    "            c=real_differentiation_scores['Differentiated']\n",
    "           )\n",
    "plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "plt.axvline(x=0.2, color='r', linestyle='--')\n",
    "plt.xlabel('Real Differentiation Score')\n",
    "plt.ylabel('Classifier: p(differentiated)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895813b-636c-45ce-b1be-0072837a0aa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Logistic regression using all datasets as training data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8449f11-ce8f-439d-b536-97700f38138d",
   "metadata": {},
   "source": [
    "This is used for creating the coefficients dataset.\n",
    "\n",
    "Often data is held in reserve for validating a model. For this reason, \n",
    "the data shall be processed once again, but using all the input data as training data. \n",
    "The results can then be used to confirm the run_logistic_regression_classifier.ipynb \n",
    "is using coefficients correctly to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6511d16-bdbc-4288-b505-a3a4207769a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run logistic regression on all the non-retained datasets\n",
    "lreg = LogisticRegression(solver='liblinear', max_iter=100, penalty='l1')\n",
    "lreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf5015-76be-4811-9de4-0e9d8e5d8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the complete results\n",
    "output_results = (expression_data\n",
    "                  .loc[:, ['Accession', 'Cell_line', 'Diff_efficiency', 'Differentiated', 'Retention_group']]\n",
    "                  .drop_duplicates()\n",
    "                  .reset_index(drop=True)\n",
    "                 )\n",
    "\n",
    "predicted = pd.DataFrame(lreg.predict(X), columns=[\"LogReg_Differentiated\"])\n",
    "predicted_proba = pd.DataFrame(lreg.predict_proba(X), columns=[\"\", \"LogReg_p(differentiated)\"])\n",
    "predicted_proba = predicted_proba.iloc[:, 1]      \n",
    "output_results = pd.concat([output_results, predicted, predicted_proba], axis=1)\n",
    " \n",
    "output_file = 'classification_results_trained_on_all_data.tsv.gz'\n",
    "print(\"Writing results to: \" + output_file)\n",
    "output_results.to_csv(output_file, index=False, compression='gzip', sep=\"\\t\")\n",
    "del(predicted, predicted_proba, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028668a2-5c45-41df-8c94-7a1ea160b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "influential_target_ids = expression_data.loc[:, 'target_id'].drop_duplicates().reset_index(drop=True)\n",
    "influential_coefficients = pd.Series(lreg.coef_[0]).reset_index(drop=True)\n",
    "influential_coefficients.name = \"coefficient\"\n",
    "\n",
    "influential_coefficients = pd.concat([influential_target_ids, influential_coefficients], axis=1)\n",
    "influential_coefficients = influential_coefficients[influential_coefficients.coefficient > 0]\n",
    "\n",
    "influential_coefficients = pd.merge(influential_coefficients, expression_data, how=\"left\", on=\"target_id\")\n",
    "influential_coefficients = (influential_coefficients\n",
    "    .loc[:, ['target_id', 'target_mean_log10_tpm', 'target_StdDev_log10_tpm', 'coefficient']]\n",
    "     .drop_duplicates()\n",
    "    ) \n",
    "      \n",
    "del(influential_target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33373d-b9ed-45bd-8e38-9f3eae51a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the intercept to the first row of the coefficients dataframe\n",
    "intercept_row =  pd.DataFrame({'target_id' : 'INTERCEPT', \n",
    "                 'target_mean_log10_tpm' : 'NA', \n",
    "                 'target_StdDev_log10_tpm' : 'NA', \n",
    "                 'coefficient' : lreg.intercept_\n",
    "                }, index=[1]\n",
    ")\n",
    "\n",
    "influential_coefficients = pd.concat([intercept_row, influential_coefficients], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a493fb-0104-436b-a155-4e211cea4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the coefficients results\n",
    "coefficents_file = 'logistic_regression_coefficients.tsv.gz'\n",
    "print(\"Writing results to: \" + coefficents_file)\n",
    "influential_coefficients.to_csv(coefficents_file, index=False, compression='gzip', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51b6de-3fcc-4387-8c90-72c8312207c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "cm = confusion_matrix(y, lreg.predict(X))\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap=plt.cm.Blues, fmt='g')\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['Undifferentiated', 'Differentiated'])\n",
    "ax.yaxis.set_ticklabels(['Undifferentiated', 'Differentiated'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f436573-e90d-45aa-a670-d8ed01c08112",
   "metadata": {},
   "source": [
    "### Model stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8989b9-7095-44c0-8109-a891bb999aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To provide an assessment of the stability of the model, logistic_regression is \n",
    "# re-run using 90% training data and 10% validation \n",
    "# (randomly selecting the data 10 * 10 = 100 times).  In what proportion of the \n",
    "# datasets is an accession classified as differentiated?\n",
    "\n",
    "# Randomly assign the Accessions to 1 of 10 groups\n",
    "number_of_interations = 5\n",
    "number_of_groups = 2\n",
    "results_collated = pd.DataFrame(columns=[\"Accession\", \"Differentiated\"])    #Uninitialised\n",
    "\n",
    "shuffle_accessions = expression_data\n",
    "\n",
    "for i in (range(number_of_interations)):\n",
    "    print(f\"Iteration {i + 1}\")\n",
    "    \n",
    "    shuffle_accessions = (shuffle_accessions\n",
    "                        .loc[:, \"Accession\"]\n",
    "                        .drop_duplicates()\n",
    "                     )\n",
    "    \n",
    "    shuffle_accessions = (shuffle_accessions\n",
    "                            .sample(frac=1)\n",
    "                            .reset_index(drop=True)\n",
    "                         )\n",
    "\n",
    "    # Recycle 0...9 to allocate each accession to a groups\n",
    "    groups = np.array(range(number_of_groups))\n",
    "    groups = pd.DataFrame(np.resize(groups, len(shuffle_accessions.index)), columns=[\"Group\"])\n",
    "    shuffle_accessions = pd.concat([shuffle_accessions, groups], axis=1)\n",
    "\n",
    "    #Create training and test NumPy arrays\n",
    "    for test_group in range(number_of_groups):\n",
    "        train_accessions = shuffle_accessions[shuffle_accessions['Group'] != test_group]\n",
    "        test_accessions = shuffle_accessions[shuffle_accessions['Group'] == test_group]\n",
    "\n",
    "        X_train = (pd.merge(train_accessions, expression_data, how=\"left\", on=\"Accession\")\n",
    "                                .loc[:, ['Accession', 'target_id', 'z_score']]\n",
    "                                .pivot(index=\"Accession\", columns='target_id', values='z_score')\n",
    "                                .sort_index(axis=1)\n",
    "                                .to_numpy()\n",
    "                            )\n",
    "\n",
    "        y_train = (pd.merge(train_accessions, expression_data, how=\"left\", on=\"Accession\")\n",
    "                                .loc[:, ['Accession', 'Differentiated']]\n",
    "                                .drop_duplicates()\n",
    "                                .sort_values(by=['Accession'])\n",
    "                                .loc[:, 'Differentiated']\n",
    "                                .to_numpy()\n",
    "                             )\n",
    "\n",
    "        X_test = (pd.merge(test_accessions, expression_data, how=\"left\", on=\"Accession\")\n",
    "                                .loc[:, ['Accession', 'target_id', 'z_score']]\n",
    "                                .pivot(index=\"Accession\", columns='target_id', values='z_score')\n",
    "                                .sort_index(axis=1)\n",
    "                                .to_numpy()\n",
    "                            )\n",
    "\n",
    "        y_test = (pd.merge(test_accessions, expression_data, how=\"left\", on=\"Accession\")\n",
    "                                .loc[:, ['Accession', 'Differentiated']]\n",
    "                                .drop_duplicates()\n",
    "                                .sort_values(by=['Accession'])\n",
    "                                .loc[:, 'Differentiated']\n",
    "                                .to_numpy()\n",
    "                             )\n",
    "\n",
    "        lreg = LogisticRegression(solver='liblinear', max_iter=100, penalty='l1')\n",
    "        lreg.fit(X_train, y_train)\n",
    "        predicted = pd.DataFrame(lreg.predict(X_test), columns=[\"Differentiated\"])\n",
    "\n",
    "        test_accessions = test_accessions.reset_index(drop=True)\n",
    "        results = pd.concat([test_accessions['Accession'], pd.DataFrame(predicted)], axis=1)\n",
    "        results_collated = results_collated.append(results)\n",
    "\n",
    "results_collated[\"Differentiated\"] = results_collated[\"Differentiated\"].astype(int)\n",
    "results_collated = results_collated.groupby(by=\"Accession\").mean()\n",
    "results_collated = results_collated.rename(columns={\"Differentiated\" : \"Mean_Differentiated\"})\n",
    "\n",
    "#xpression_data.loc[:, ['Accession', 'Differentiated']].drop_duplicates().head()\n",
    "lreg = LogisticRegression(solver='liblinear', max_iter=100, penalty='l1')\n",
    "lreg.fit(X_train, y_train)\n",
    "\n",
    "actual = y_test\n",
    "predicted = lreg.predict(X_test)\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(actual, predicted)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap=plt.cm.Blues, fmt='g')\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['Undifferentiated', 'Differentiated'])\n",
    "ax.yaxis.set_ticklabels(['Undifferentiated', 'Differentiated'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ec3c6-a20f-4753-b469-193e4a40bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To provide an assessment of the stability of the model, logistic_regression is \n",
    "# re-run using 90% training data and 10% validation \n",
    "# (randomly selecting the data 10 * 10 = 100 times).  In what proportion of the \n",
    "# datasets is an accession classified as differentiated?\n",
    "\n",
    "# Randomly assign the Accessions to 1 of 10 groups\n",
    "number_of_interations = 100\n",
    "number_of_groups = 10\n",
    "results_collated = pd.DataFrame(columns=[\"Accession\", \"Differentiated\"])    #Uninitialised\n",
    "\n",
    "#List of accessions\n",
    "shuffled_accessions = expression_data['Accession'].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "for i in (range(number_of_interations)):\n",
    "    if((i + 1) % 5 == 0):\n",
    "        print(f\"Iteration {i + 1}\")\n",
    "\n",
    "    #shuffled_accessions = shuffled_accessions[::-1]\n",
    "    shuffled_accessions = (shuffled_accessions\n",
    "                            .sample(frac=1)\n",
    "                            .reset_index(drop=True)    #Required, else identical accessions chosen each time\n",
    "                           )\n",
    "\n",
    "    # Divide accession into 10 approximately equally sized groups, 1 of which is the test group\n",
    "    accession_groups = np.array(range(number_of_groups))\n",
    "    accession_groups = pd.DataFrame(np.resize(accession_groups, len(shuffle_accessions.index)), columns=[\"Group\"])\n",
    "\n",
    "\n",
    "    #Identify train/test data\n",
    "    for test_group in range(number_of_groups):\n",
    "        train_accessions = shuffled_accessions.loc[accession_groups[\"Group\"] != test_group]\n",
    "        test_accessions = shuffled_accessions.loc[accession_groups[\"Group\"] == test_group] \n",
    "\n",
    "        train_data = pd.merge(train_accessions, expression_data, how=\"left\", on=\"Accession\")\n",
    "        train_data = train_data.loc[:, ['Accession', 'Differentiated', 'target_id', 'z_score']]\n",
    "        test_data = pd.merge(test_accessions, expression_data, how=\"left\", on=\"Accession\")\n",
    "        test_data = test_data.loc[:, ['Accession', 'Differentiated', 'target_id', 'z_score']]\n",
    "\n",
    "        #Convert to NumPy format for logistic regression classifier\n",
    "        X_train = (train_data\n",
    "                        .loc[:, ['Accession', 'target_id', 'z_score']]\n",
    "                        .pivot(index=\"Accession\", columns='target_id', values='z_score')\n",
    "                        .sort_index(axis=1)\n",
    "                        .to_numpy()\n",
    "                  )\n",
    "\n",
    "        y_train = (train_data\n",
    "                        .loc[:, ['Accession', 'Differentiated']]\n",
    "                        .drop_duplicates()\n",
    "                        .sort_values(by=['Accession'])\n",
    "                        .loc[:, 'Differentiated']\n",
    "                        .to_numpy()\n",
    "                    )\n",
    "\n",
    "        X_test = (test_data\n",
    "                        .loc[:, ['Accession', 'target_id', 'z_score']]\n",
    "                        .pivot(index=\"Accession\", columns='target_id', values='z_score')\n",
    "                        .sort_index(axis=1)\n",
    "                        .to_numpy()\n",
    "                  )\n",
    "\n",
    "        y_test = (test_data\n",
    "                        .loc[:, ['Accession', 'Differentiated']]\n",
    "                        .drop_duplicates()\n",
    "                        .sort_values(by=['Accession'])\n",
    "                        .loc[:, 'Differentiated']\n",
    "                        .to_numpy()\n",
    "                    )\n",
    "\n",
    "        lreg = LogisticRegression(solver='liblinear', max_iter=100, penalty='l1')\n",
    "        lreg.fit(X_train, y_train)\n",
    "        predicted = pd.DataFrame(lreg.predict(X_test), columns=[\"Differentiated\"])\n",
    "\n",
    "        test_accessions = (test_accessions\n",
    "                           .sort_values()\n",
    "                           .reset_index(drop=True)\n",
    "                          )  #It was sorted previouly\n",
    "        \n",
    "        results = pd.concat([test_accessions, pd.DataFrame(predicted)], axis=1)\n",
    "        results_collated = results_collated.append(results)        \n",
    "\n",
    "results_collated[\"Differentiated\"] = results_collated[\"Differentiated\"].astype(int)\n",
    "results_collated = results_collated.groupby(by=\"Accession\").mean()\n",
    "results_collated = results_collated.rename(columns={\"Differentiated\" : \"Mean_Differentiated\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3be5c9-4e5f-4cca-a02c-cd6c6be2c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the p(differentiated) of all data vs stability \n",
    "pdiff_vs_stability = pd.merge(output_results, results_collated, how=\"inner\", on=\"Accession\")\n",
    "\n",
    "plt.figure(figsize=(14, 10)) \n",
    "\n",
    "plt.scatter(x=pdiff_vs_stability['LogReg_p(differentiated)'], \n",
    "            y=pdiff_vs_stability['Mean_Differentiated'],\n",
    "            c=pdiff_vs_stability['Differentiated']\n",
    "           )\n",
    "plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "plt.axvline(x=0.5, color='r', linestyle='--')\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('Logistic Regression p(differentiated)')\n",
    "plt.ylabel('Proporton Differentiated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e8aee-0925-41e2-8092-052069ea4143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
