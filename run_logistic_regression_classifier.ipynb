{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfa43cc-b230-4954-ae1c-92327f5446df",
   "metadata": {},
   "source": [
    "# Run Logistic Regression Classifier Model to Predict Expression Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf811a-98e0-42a7-9bbb-9e6a25b0037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee8212-5784-4580-8196-0bb5936e372c",
   "metadata": {},
   "source": [
    "## Setup(edit as required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56715d5b-54e1-44c3-8283-9edc5c84b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (edit as required)\n",
    "expression_datafile = 'classifier_input.tsv.gz'\n",
    "differentiation_threshold = 0.2  #Set in paper\n",
    "coefficents_file = 'logistic_regression_coefficients.tsv.gz'\n",
    "collated_coefficients_file = 'collated_logistic_regression_coefficients.tsv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae9369-bd37-4bc9-8dbb-2476ded76b3f",
   "metadata": {},
   "source": [
    "## Data overview and QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1c9cf-338a-434d-82b6-857c14a7f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "expression_data = pd.read_csv(expression_datafile, sep=\"\\t\")\n",
    "print(\"Reading in: \" + expression_datafile)\n",
    "print(\"Number of different accessions: \" + str(expression_data['Accession'].drop_duplicates().count()))\n",
    "print(\"Number of different cell lines: \" + str(expression_data['Cell_line'].drop_duplicates().count()))\n",
    "print(\"Number of different transcripts: \" + str(expression_data['target_id'].drop_duplicates().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4111de-33e9-457b-a64d-f0a53acd602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log10 tpm histogram\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(expression_data['log10_tpm'], bins=100)\n",
    "plt.xlabel('Log10(tpm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a9c03-b922-48fd-adc7-766bae776f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot=sns.ecdfplot(data=expression_data, \n",
    "                  x=\"log10_tpm\", \n",
    "                  hue=\"Accession\",\n",
    "                 legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef837a4-9a62-44c0-99d0-347cbee56d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are using an already established logistic regression model, the expression\n",
    "# DataFrame my be simplified to only include relevant data\n",
    "expression_data = (expression_data\n",
    "        .loc[:, ['Accession', 'target_id', 'Cell_line', 'log10_tpm']]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe31c35-138a-479b-9f6d-c97f2f66e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a simplified file in user-friendly format for analysis in other tools (e.g. R, Excel)\n",
    "\n",
    "#Log10(TPM+1)\n",
    "data_for_external_analysis = expression_data\n",
    "data_for_external_analysis['Cell_Sample'] = data_for_external_analysis['Accession'] + \"_\" + data_for_external_analysis['Cell_line']\n",
    "\n",
    "data_for_external_analysis = (data_for_external_analysis\n",
    "        .loc[:, ['Cell_Sample', 'target_id', 'log10_tpm']]\n",
    "        .pivot(index=\"target_id\", columns='Cell_Sample', values='log10_tpm')\n",
    "    )\n",
    "\n",
    "data_for_external_analysis['Cell_Sample'] = data_for_external_analysis.index\n",
    "first_column = data_for_external_analysis.pop('Cell_Sample')\n",
    "data_for_external_analysis.insert(0, 'Cell_Sample', first_column)\n",
    "\n",
    "\n",
    "#Write out the result\n",
    "external_analysis_file = 'external_analysis_data_log10_tpm.tsv.gz'\n",
    "print(\"Writing results to: \" + external_analysis_file)\n",
    "data_for_external_analysis.to_csv(external_analysis_file, index=False, compression='gzip', sep=\"\\t\")\n",
    "\n",
    "del(data_for_external_analysis)\n",
    "del(first_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583742a-8f0d-49e3-b146-109332956f36",
   "metadata": {},
   "source": [
    "## Run Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a493fb-0104-436b-a155-4e211cea4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import coefficients\n",
    "print(\"Reading in coefficients file: \" + coefficents_file)\n",
    "coefficients = pd.read_csv(coefficents_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fce155-1990-47cf-9761-30bf5e0fb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intercept\n",
    "if(coefficients.loc[0, 'target_id'] != 'INTERCEPT'):\n",
    "    print(\"Intercept not found in \" + coefficents_file)\n",
    "intercept = coefficients.loc[0, 'coefficient']\n",
    "    \n",
    "coefficients.drop(axis=0, index=0, inplace=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461a1e1-6006-4a7b-b6bf-56434a6e28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Coefficients data with expression data\n",
    "coefficient_transcripts = (coefficients\n",
    "                               .loc[:, \"target_id\"]\n",
    "                               .drop_duplicates()\n",
    "                          )\n",
    "\n",
    "expression_transcripts = (expression_data\n",
    "                            .loc[:, \"target_id\"]\n",
    "                            .drop_duplicates()\n",
    "                          )\n",
    "\n",
    "not_found_coefficients = coefficient_transcripts[coefficient_transcripts.isin(expression_transcripts)==False]\n",
    "\n",
    "if(not_found_coefficients.size == 0):\n",
    "    print(\"Good news: all logistic regression coefficients found in expression data\")\n",
    "    expression_data_key_transcripts = pd.merge(expression_data, coefficients, how=\"inner\", on=\"target_id\")\n",
    "else:\n",
    "    print(\"Warning: coefficients missing in input expression data:\")\n",
    "    print(not_found_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882208da-2a60-4830-904a-6ec993053aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(differentiated) for each accession\n",
    "\n",
    "# Calculate Z-scores using the mean and stdev from the pre-computed logistric regression model\n",
    "expression_data_key_transcripts['z_score'] = (expression_data_key_transcripts['log10_tpm'] -  expression_data_key_transcripts['target_mean_log10_tpm']) / expression_data_key_transcripts['target_StdDev_log10_tpm']\n",
    "\n",
    "#Mutiply z-score by coefficients\n",
    "expression_data_key_transcripts['weighting'] = expression_data_key_transcripts['z_score'] * expression_data_key_transcripts['coefficient']\n",
    "\n",
    "# Sum weightings\n",
    "weightings = (expression_data_key_transcripts\n",
    "              .loc[:, [\"Accession\", \"weighting\"]]\n",
    "              .groupby(by='Accession')\n",
    "              .sum()\n",
    "             )\n",
    "\n",
    "weightings['Accession'] = weightings.index\n",
    "weightings = weightings.reset_index(drop=True)\n",
    "\n",
    "#Add intercept value\n",
    "weightings[\"weighting_plus_intercept\"] = weightings[\"weighting\"] + intercept\n",
    "\n",
    "#Calculate probability\n",
    "#P(t) = 1 / (1 + e^(-t))\n",
    "weightings[\"LogReg_p(differentiated)\"] = 0 - weightings[\"weighting_plus_intercept\"]\n",
    "weightings[\"LogReg_p(differentiated)\"] = weightings[\"LogReg_p(differentiated)\"].apply(lambda x: math.exp(x))\n",
    "weightings[\"LogReg_p(differentiated)\"] = 1 / (1 + weightings[\"LogReg_p(differentiated)\"])\n",
    "\n",
    "weightings[\"Differentiated\"] = weightings[\"LogReg_p(differentiated)\"] >= 0.5\n",
    "weightings[\"Differentiated\"] = weightings[\"Differentiated\"].astype(int)\n",
    "\n",
    "weightings = (weightings\n",
    "               .loc[:, [\"Accession\", \"LogReg_p(differentiated)\", \"Differentiated\"]]\n",
    "             )\n",
    "\n",
    "results = weightings\n",
    "del(weightings)\n",
    "del(expression_data_key_transcripts)\n",
    "\n",
    "results = results.sort_values(by=\"LogReg_p(differentiated)\", axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b76862-50f4-46d4-ac42-cc0faabd49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot results\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Accession\", \n",
    "                 y=\"LogReg_p(differentiated)\",\n",
    "                 color=\"teal\",\n",
    "                 data=results)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0, 1)\n",
    "plt.axhline(y=0.5, color='black', linestyle='--')\n",
    "\n",
    "if(results.shape[0] > 50):    #Show axis labels for smaller datasets\n",
    "    plt.tick_params(labelbottom=False) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09d869-8307-4ef0-8c5a-0d9be901ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the results\n",
    "results_file = \"run_classification_results.tsv.gz\"\n",
    "print(\"Writing results to: \" + results_file)\n",
    "results.to_csv(results_file, index=False, compression='gzip', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d00b83f-ed1d-44b2-bc1e-ffe90a3ff671",
   "metadata": {},
   "source": [
    "## Prediction Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bfacfc-a673-4146-a59a-68499b43f105",
   "metadata": {},
   "source": [
    "The build_logistic_regression_classifier.ipynb Jupyter Notebook performs multiple logistic regressions on subsets of the training data, to determine the stability of a prediction.  The resulting coefficients from these classifications are written to an output file.  Here, these coefficients (and intercepts) from multiple logistic regression are read in and used to perform muliple logistic regressions on the new datasets of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe6e2f-2be9-492f-bbe8-4bbdaee16cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import coefficients\n",
    "print(\"Reading in multiple coefficients file: \" + collated_coefficients_file)\n",
    "collated_coefficients = pd.read_csv(collated_coefficients_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb249ed-b4a9-424f-8081-93bd66cf7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the logistic regression groups\n",
    "logistic_regression_iteration_ids = (collated_coefficients['logistic_regression_iteration']\n",
    "                                     .drop_duplicates()\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653cbef-97e9-4e00-a272-aa4ad668ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intercepts\n",
    "intercepts = collated_coefficients[collated_coefficients['target_id'] == 'INTERCEPT']\n",
    "collated_coefficients = collated_coefficients[collated_coefficients['target_id'] != 'INTERCEPT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927dfbd7-9ce1-46b0-9275-85fe96566a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge collated coefficients with expression data\n",
    "# Doing this once is most likely more efficient than perfomring a merge 1000s of times\n",
    "collated_coefficient_transcripts = (collated_coefficients\n",
    "                                       .loc[:, \"target_id\"]\n",
    "                                       .drop_duplicates()\n",
    "                                      )\n",
    "\n",
    "expression_transcripts = (expression_data\n",
    "                            .loc[:, \"target_id\"]\n",
    "                            .drop_duplicates()\n",
    "                          )\n",
    "\n",
    "not_found_coefficients = collated_coefficient_transcripts[collated_coefficient_transcripts.isin(expression_transcripts)==False]\n",
    "\n",
    "if(not_found_coefficients.size == 0):\n",
    "    print(\"Good news: all collated logistic regression coefficients found in expression data\")\n",
    "    expression_data = pd.merge(expression_data, collated_coefficients, how=\"inner\", on=\"target_id\")\n",
    "else:\n",
    "    print(\"Warning: coefficients missing in input expression data:\")\n",
    "    print(not_found_coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9626a-bd78-467a-9c3c-25cce5abfcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate P(differentiated) for each accession for each logistic regression iteraction\n",
    "collated_results = pd.DataFrame()    #Uninitialised dataframe\n",
    "\n",
    "for i in logistic_regression_iteration_ids:\n",
    "    expression_data_of_interest = (expression_data\n",
    "                                        .query(\"logistic_regression_iteration == @i\")\n",
    "                                        .reset_index()\n",
    "     )\n",
    "        \n",
    "    # Calculate Z-scores using the mean and stdev from the pre-computed logistric regression model\n",
    "    expression_data_of_interest['z_score'] = expression_data_of_interest['log10_tpm'] - expression_data_of_interest['target_mean_log10_tpm']\n",
    "    expression_data_of_interest['z_score'] = expression_data_of_interest['z_score'] / expression_data_of_interest['target_StdDev_log10_tpm']\n",
    "    \n",
    "    #Mutiply z-score by coefficients\n",
    "    expression_data_of_interest['weighting'] = expression_data_of_interest['z_score'] * expression_data_of_interest['coefficient']\n",
    "\n",
    "    # Sum weightings\n",
    "    weightings = (expression_data_of_interest\n",
    "                  .loc[:, [\"Accession\", \"weighting\"]]\n",
    "                  .groupby(by='Accession')\n",
    "                  .sum()\n",
    "                 )\n",
    "\n",
    "    weightings = weightings.reset_index()\n",
    "\n",
    "    #Add intercept value\n",
    "    weightings[\"weighting_plus_intercept\"] = weightings[\"weighting\"] + intercept\n",
    "\n",
    "    #Calculate probability\n",
    "    #P(t) = 1 / (1 + e^(-t))\n",
    "    weightings[\"LogReg_p(differentiated)\"] = 0 - weightings[\"weighting_plus_intercept\"]\n",
    "    weightings[\"LogReg_p(differentiated)\"] = weightings[\"LogReg_p(differentiated)\"].apply(lambda x: math.exp(x))\n",
    "    weightings[\"LogReg_p(differentiated)\"] = 1 / (1 + weightings[\"LogReg_p(differentiated)\"])\n",
    "\n",
    "    weightings[\"Differentiated\"] = weightings[\"LogReg_p(differentiated)\"] >= 0.5\n",
    "\n",
    "    weightings = (weightings\n",
    "                   .loc[:, [\"Accession\", \"LogReg_p(differentiated)\", \"Differentiated\"]]\n",
    "                 )\n",
    "\n",
    "    stability_results = weightings\n",
    "    del(weightings)\n",
    "\n",
    "    stability_results = stability_results.sort_values(by='Accession', axis=0, ascending=False)\n",
    "    collated_results = collated_results.append(stability_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f56bc-ed7a-4da7-b69c-86350276e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate the collated results and incorporate the output logistic regression result from before\n",
    "collated_results = (collated_results\n",
    "        .loc[:, ['Accession', 'Differentiated']]\n",
    "        .assign(Mean_Differentiated=collated_results['Differentiated'].astype(int))\n",
    "        .loc[:, ['Accession', 'Mean_Differentiated']]\n",
    "        .groupby(by='Accession')\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "collated_results = pd.merge(results, collated_results, how='left', on='Accession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea53c5-0ded-4ecf-ac81-210012dde134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the stability results\n",
    "plt.figure(figsize=(14, 10)) \n",
    "\n",
    "plt.scatter(x=collated_results['LogReg_p(differentiated)'], \n",
    "            y=collated_results['Mean_Differentiated'],\n",
    "           )\n",
    "plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "plt.axvline(x=0.5, color='r', linestyle='--')\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('Logistic Regression p(differentiated)')\n",
    "plt.ylabel('Proporton Differentiated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29050ff5-db2d-4a8c-9c4b-7e9fd554f436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Write out the result\n",
    "stability_analysis_file = 'run_classification_stability_results.tsv.gz'\n",
    "print(\"Writing results to: \" + stability_analysis_file)\n",
    "collated_results.to_csv(stability_analysis_file, index=False, compression='gzip', sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
